{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "WandBExperiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwSz4ruLsITK",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:25:38.252871Z",
          "iopub.execute_input": "2021-11-15T15:25:38.253065Z",
          "iopub.status.idle": "2021-11-15T15:26:06.058958Z",
          "shell.execute_reply.started": "2021-11-15T15:25:38.253042Z",
          "shell.execute_reply": "2021-11-15T15:26:06.058039Z"
        },
        "trusted": true
      },
      "source": [
        "!pip install -q python-Levenshtein\n",
        "!pip install -q wandb --upgrade\n",
        "!pip install -q torch_optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TVtmZpIsITG",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:06.061714Z",
          "iopub.execute_input": "2021-11-15T15:26:06.063023Z",
          "iopub.status.idle": "2021-11-15T15:26:12.394622Z",
          "shell.execute_reply.started": "2021-11-15T15:26:06.06298Z",
          "shell.execute_reply": "2021-11-15T15:26:12.393661Z"
        },
        "trusted": true
      },
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import torch.cuda.amp as amp\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import torch_optimizer as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from Levenshtein import distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W6y_Y2qsITM",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:12.396193Z",
          "iopub.execute_input": "2021-11-15T15:26:12.396514Z",
          "iopub.status.idle": "2021-11-15T15:26:14.188678Z",
          "shell.execute_reply.started": "2021-11-15T15:26:12.396476Z",
          "shell.execute_reply": "2021-11-15T15:26:14.18787Z"
        },
        "trusted": true
      },
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login(key='Your Key')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fPwZd09sITN",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:14.191178Z",
          "iopub.execute_input": "2021-11-15T15:26:14.191627Z",
          "iopub.status.idle": "2021-11-15T15:26:14.196292Z",
          "shell.execute_reply.started": "2021-11-15T15:26:14.191587Z",
          "shell.execute_reply": "2021-11-15T15:26:14.195636Z"
        },
        "trusted": true
      },
      "source": [
        "config = dict(\n",
        "    epochs=1,\n",
        "    dev_ratio=.2,\n",
        "    num_workers=4,\n",
        "    batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    seed=42,\n",
        "    amp=False,\n",
        "    optimizer='AdamW',\n",
        "    scheduler=False,\n",
        "    architecture=\"klue/bert-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:14.19762Z",
          "iopub.execute_input": "2021-11-15T15:26:14.198122Z",
          "iopub.status.idle": "2021-11-15T15:26:14.208892Z",
          "shell.execute_reply.started": "2021-11-15T15:26:14.198087Z",
          "shell.execute_reply": "2021-11-15T15:26:14.207987Z"
        },
        "trusted": true,
        "id": "qN1t4azp1jzr"
      },
      "source": [
        "platform = 'Kaggle'\n",
        "\n",
        "if platform == 'Kaggle':\n",
        "    data_path = 'Your Path'\n",
        "elif platform == 'Colab':\n",
        "    data_path = 'Your Path'  \n",
        "else:\n",
        "    print('Again!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlFjKV5AsITO",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:14.210359Z",
          "iopub.execute_input": "2021-11-15T15:26:14.210863Z",
          "iopub.status.idle": "2021-11-15T15:26:20.940061Z",
          "shell.execute_reply.started": "2021-11-15T15:26:14.210825Z",
          "shell.execute_reply": "2021-11-15T15:26:20.939267Z"
        },
        "trusted": true
      },
      "source": [
        "wandb.init(project='Your Name', entity=\"Your Entity\", config=config)\n",
        "wandb.run.name = 'Your Name'\n",
        "wandb.run.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Zx5yaZ1jzs"
      },
      "source": [
        "sweep_config = dict(\n",
        "    epochs=4,\n",
        "    dev_ratio=.2,\n",
        "    num_workers=4,\n",
        "    batch_size=16,\n",
        "    learning_rate=5e-5,\n",
        "    seed=42,\n",
        "    amp=True,\n",
        "    optimizer='RAdam',\n",
        "    scheduler=True,\n",
        "    architecture=\"klue/roberta-base\")\n",
        "\n",
        "sweep_config = {\n",
        "    \"name\" : \"my-sweep\",\n",
        "    \"method\" : \"bayes\",\n",
        "    \n",
        "    \"metric\" : {\n",
        "       \"goal\": 'minimize',\n",
        "       \"name\": 'eval_loss'\n",
        "    }\n",
        "    \"parameters\" :{\n",
        "        \"epochs\" : {\n",
        "            \"max\" : 5,\n",
        "            \"min\" : 2,\n",
        "            \"distribution\": \"int_uniform\"\n",
        "\n",
        "        },\n",
        "        \"learning_rate\" :{\n",
        "            \"min\": 5e-5,\n",
        "            \"max\": 1e-5\n",
        "        },\n",
        "        \"batch_size\":{\n",
        "            \"values\": [4,8,16]\n",
        "        },\n",
        "        \"optimizer\":{\n",
        "            \"values\": ['RAdam, AdamW']\n",
        "        },\n",
        "        \"scheduler\":{\n",
        "            \"values\": [True, False]\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqXC0pFsITP",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:20.941783Z",
          "iopub.execute_input": "2021-11-15T15:26:20.942174Z",
          "iopub.status.idle": "2021-11-15T15:26:20.94729Z",
          "shell.execute_reply.started": "2021-11-15T15:26:20.94211Z",
          "shell.execute_reply": "2021-11-15T15:26:20.946609Z"
        },
        "trusted": true
      },
      "source": [
        "wandb.config.update(config)\n",
        "config = wandb.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuot6EgSoBmv",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:20.948563Z",
          "iopub.execute_input": "2021-11-15T15:26:20.949091Z",
          "iopub.status.idle": "2021-11-15T15:26:20.96193Z",
          "shell.execute_reply.started": "2021-11-15T15:26:20.949054Z",
          "shell.execute_reply": "2021-11-15T15:26:20.961131Z"
        },
        "trusted": true
      },
      "source": [
        "def set_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "set_seeds(seed=config.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA_m4qaLsITQ",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:20.96317Z",
          "iopub.execute_input": "2021-11-15T15:26:20.964717Z",
          "iopub.status.idle": "2021-11-15T15:26:22.333433Z",
          "shell.execute_reply.started": "2021-11-15T15:26:20.964685Z",
          "shell.execute_reply": "2021-11-15T15:26:22.33265Z"
        },
        "trusted": true
      },
      "source": [
        "with open(f\"{data_path}/train.json\", 'rb') as f:\n",
        "    data_dict = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRYoz_2fsITQ",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:22.336296Z",
          "iopub.execute_input": "2021-11-15T15:26:22.336564Z",
          "iopub.status.idle": "2021-11-15T15:26:22.343915Z",
          "shell.execute_reply.started": "2021-11-15T15:26:22.336528Z",
          "shell.execute_reply": "2021-11-15T15:26:22.34286Z"
        },
        "trusted": true
      },
      "source": [
        "def read_data(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        data_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for group in tqdm(data_dict['data']):\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "  \n",
        "\n",
        "    return contexts, questions, answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmGgsc2ZsITR",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:22.345354Z",
          "iopub.execute_input": "2021-11-15T15:26:22.345812Z",
          "iopub.status.idle": "2021-11-15T15:26:22.35605Z",
          "shell.execute_reply.started": "2021-11-15T15:26:22.345773Z",
          "shell.execute_reply": "2021-11-15T15:26:22.355253Z"
        },
        "trusted": true
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNFaKURcsITR",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:22.359112Z",
          "iopub.execute_input": "2021-11-15T15:26:22.359417Z",
          "iopub.status.idle": "2021-11-15T15:26:28.387952Z",
          "shell.execute_reply.started": "2021-11-15T15:26:22.359389Z",
          "shell.execute_reply": "2021-11-15T15:26:28.387222Z"
        },
        "trusted": true
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9slr9KnvsITT",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:28.389149Z",
          "iopub.execute_input": "2021-11-15T15:26:28.389442Z",
          "iopub.status.idle": "2021-11-15T15:26:28.405112Z",
          "shell.execute_reply.started": "2021-11-15T15:26:28.389403Z",
          "shell.execute_reply": "2021-11-15T15:26:28.404433Z"
        },
        "trusted": true
      },
      "source": [
        "class CustomedDataset(Dataset):\n",
        "    def __init__(self, contexts, questions, answers, model_max_position_embedings, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.answers = answers\n",
        "        self.questions = questions\n",
        "        self.contexts = contexts\n",
        "        self.model_max_position_embedings = model_max_position_embedings\n",
        "        print(\"Tokenizing ...\")\n",
        "        self.encodings = self.tokenizer(self.contexts,\n",
        "                                        self.questions,\n",
        "                                        max_length=512,\n",
        "                                        truncation='only_first',\n",
        "                                        padding=\"max_length\",\n",
        "                                        return_token_type_ids=False)\n",
        "\n",
        "        print(\"Done !!!\")\n",
        "        self.add_token_positions()\n",
        "        \n",
        "    def add_token_positions(self):\n",
        "\n",
        "        start_positions = []\n",
        "        end_positions = []\n",
        "        for i in range(len(self.answers)):\n",
        "            start_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_start']))\n",
        "            end_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_end'] - 1))\n",
        "    \n",
        "            if start_positions[-1] is None:\n",
        "                start_positions[-1] = self.model_max_position_embedings\n",
        "            if end_positions[-1] is None:\n",
        "                end_positions[-1] = self.model_max_position_embedings\n",
        "        self.encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "        \n",
        "    def get_data(self):\n",
        "        return {\"contexts\":self.contexts, 'questions':self.questions, 'answers':self.answers}\n",
        "    \n",
        "    \n",
        "    def get_encodings(self):\n",
        "        return self.encodings\n",
        "        \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {key:torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UxS4hJpsITU",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:28.406512Z",
          "iopub.execute_input": "2021-11-15T15:26:28.40692Z",
          "iopub.status.idle": "2021-11-15T15:26:28.709518Z",
          "shell.execute_reply.started": "2021-11-15T15:26:28.406881Z",
          "shell.execute_reply": "2021-11-15T15:26:28.706138Z"
        },
        "trusted": true
      },
      "source": [
        "contexts, questions, answers = read_data(f\"{data_path}/train.json\")\n",
        "add_end_idx(answers, contexts)\n",
        "\n",
        "\n",
        "def train_test_split(contexts, questions, answers, ratio =.2):\n",
        "    num_ratio = int(len(contexts) * ratio)\n",
        "    return contexts[num_ratio:], questions[num_ratio:], answers[num_ratio:], contexts[:num_ratio], questions[:num_ratio], answers[:num_ratio],\n",
        "\n",
        "train_contexts, train_questions, train_answers, dev_contexts, dev_questions, dev_answers = train_test_split(contexts, questions, answers, ratio = config.dev_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q3vaBSjsITW",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:28.720464Z",
          "iopub.execute_input": "2021-11-15T15:26:28.7211Z",
          "iopub.status.idle": "2021-11-15T15:26:45.907946Z",
          "shell.execute_reply.started": "2021-11-15T15:26:28.72106Z",
          "shell.execute_reply": "2021-11-15T15:26:45.907236Z"
        },
        "trusted": true
      },
      "source": [
        "train_dataset = CustomedDataset(train_contexts, train_questions, train_answers, 512, tokenizer)\n",
        "dev_dataset = CustomedDataset(dev_contexts, dev_questions, dev_answers, 512, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tck89yNTsITW",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:45.909359Z",
          "iopub.execute_input": "2021-11-15T15:26:45.909618Z",
          "iopub.status.idle": "2021-11-15T15:26:45.918336Z",
          "shell.execute_reply.started": "2021-11-15T15:26:45.909581Z",
          "shell.execute_reply": "2021-11-15T15:26:45.917506Z"
        },
        "trusted": true
      },
      "source": [
        "print(len(train_dataset), len(dev_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVMSy0lRsITW",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:45.927529Z",
          "iopub.execute_input": "2021-11-15T15:26:45.928129Z",
          "iopub.status.idle": "2021-11-15T15:26:59.222956Z",
          "shell.execute_reply.started": "2021-11-15T15:26:45.928095Z",
          "shell.execute_reply": "2021-11-15T15:26:59.222238Z"
        },
        "trusted": true
      },
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(\"klue/bert-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GCDEjx9sITX",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:59.224467Z",
          "iopub.execute_input": "2021-11-15T15:26:59.224719Z",
          "iopub.status.idle": "2021-11-15T15:26:59.254963Z",
          "shell.execute_reply.started": "2021-11-15T15:26:59.224685Z",
          "shell.execute_reply": "2021-11-15T15:26:59.254115Z"
        },
        "trusted": true
      },
      "source": [
        "def train_runner(model, train_dataset, dev_dataset, dev_answers, config):\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                                  batch_size=config.batch_size,\n",
        "                                  shuffle=True,\n",
        "                                  pin_memory=True,\n",
        "                                  num_workers=config.num_workers)\n",
        "    \n",
        "    dev_loader = DataLoader(dataset=dev_dataset,\n",
        "                            batch_size=config.batch_size,\n",
        "                            shuffle=False,\n",
        "                            pin_memory=True,\n",
        "                            num_workers=config.num_workers)\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    def get_learning_rate(optimizer):\n",
        "      lr=[]\n",
        "      for param_group in optimizer.param_groups:\n",
        "          lr +=[ param_group['lr'] ]\n",
        "\n",
        "      assert(len(lr)==1) \n",
        "      lr = lr[0]\n",
        "\n",
        "      return lr\n",
        "\n",
        "    global_total_step = len(train_loader) * config.epochs\n",
        "    if config.optimizer == 'AdamW':\n",
        "        optimizer = AdamW(model.parameters(), lr=config.learning_rate)\n",
        "    else:\n",
        "        optimizer = optim.Lookahead(optim.RAdam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate), alpha=0.5, k=5)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = global_total_step)\n",
        "    scaler = amp.GradScaler()\n",
        "    \n",
        "\n",
        "    wandb.watch(model, log='all', log_freq=10)\n",
        "    \n",
        "    preds = []\n",
        "    \n",
        "    for epoch in range(config.epochs):\n",
        "        with tqdm(train_loader, unit=\"batch\", desc='Train') as t:\n",
        "            total = 0\n",
        "            total_loss = 0\n",
        "        \n",
        "            start = time.time()\n",
        "            lr = get_learning_rate(optimizer)\n",
        "            wandb.log({'learning_rate': lr})\n",
        "            print(f'learning rate : {lr : .6f}')\n",
        "            for i, batch in enumerate(train_loader):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                start_positions = batch['start_positions'].to(device)\n",
        "                end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                if config.amp:\n",
        "                  with amp.autocast():\n",
        "                    outputs = model(input_ids,\n",
        "                                    attention_mask=attention_mask,\n",
        "                                    start_positions=start_positions,\n",
        "                                    end_positions=end_positions)\n",
        "\n",
        "                    loss = outputs.loss\n",
        "                  scaler.scale(loss).backward()\n",
        "                  scaler.step(optimizer)\n",
        "                  scaler.update()\n",
        "                else:\n",
        "                  outputs = model(input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  start_positions=start_positions,\n",
        "                                  end_positions=end_positions)\n",
        "                  loss = outputs.loss\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "                if config.scheduler:\n",
        "                    scheduler.step()\n",
        "                \n",
        "                batch_loss = loss.item() * len(input_ids)\n",
        "                total += len(input_ids)\n",
        "                total_loss += batch_loss\n",
        "                global_total_step += 1\n",
        "\n",
        "                wandb.log({'epoch': epoch, 'loss': total_loss / total, 'batch_loss': batch_loss})\n",
        "                t.set_postfix(loss=\"{:.6f}\".format(total_loss / total), batch_loss=\"{:.6f}\".format(batch_loss))\n",
        "                t.update(1)\n",
        "\n",
        "                del input_ids, attention_mask, start_positions, end_positions, outputs, loss\n",
        "            \n",
        "            end = time.time()\n",
        "            print('Train End! Total time spent: ', end-start)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            losses = []\n",
        "            levs = []\n",
        "            exact_match = 0          \n",
        "            count = 0\n",
        "\n",
        "            model.eval()\n",
        "            for batch in tqdm(dev_loader, unit=\"batch\", desc='Evaluate'):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                start_positions = batch['start_positions'].to(device)\n",
        "                end_positions = batch['end_positions'].to(device)\n",
        "                \n",
        "                if config.amp:\n",
        "                  with amp.autocast():\n",
        "                    outputs = model(input_ids,\n",
        "                                    attention_mask=attention_mask,\n",
        "                                    start_positions=start_positions,\n",
        "                                    end_positions=end_positions)\n",
        "                    loss = outputs.loss\n",
        "                else:\n",
        "                  outputs = model(input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  start_positions=start_positions,\n",
        "                                  end_positions=end_positions)\n",
        "                  loss = outputs.loss\n",
        "                \n",
        "                start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
        "                token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n",
        "                for i in range(len(batch)):\n",
        "                    pred_id = input_ids[i][token_start_index[i]: token_end_index[i] + 1]\n",
        "                    pred = tokenizer.decode(pred_id)\n",
        "                 \n",
        "                    if epoch == config.epochs - 1:\n",
        "                      preds.append(pred)\n",
        "                    \n",
        "                    lev = distance(pred, dev_answers[count]['text'])\n",
        "                    levs.append(lev)\n",
        "                  \n",
        "                    if pred in dev_answers[count]['text']:\n",
        "                      exact_match += 1\n",
        "                    \n",
        "                    count += 1\n",
        "                \n",
        "                losses.append(loss.item())\n",
        "                \n",
        "                batch_loss = loss.item() * len(input_ids)\n",
        "                del input_ids, attention_mask, start_positions, end_positions, outputs, loss, lev\n",
        "            \n",
        "            em_score = exact_match / len(levs)\n",
        "            loss = sum(losses) / len(losses)\n",
        "            lev = sum(levs)/ len(levs)\n",
        "            wandb.log({'eval_loss': loss,'Levenshtein': lev, 'em_score': em_score })\n",
        "                       \n",
        "    model.save_pretrained(\"Your Path\")\n",
        "    print('Eval Loss: ',loss)\n",
        "    print(\"TRAIN END\")\n",
        "\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOE7bcuQsITY",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:59.256528Z",
          "iopub.execute_input": "2021-11-15T15:26:59.25683Z",
          "iopub.status.idle": "2021-11-15T15:26:59.279157Z",
          "shell.execute_reply.started": "2021-11-15T15:26:59.256793Z",
          "shell.execute_reply": "2021-11-15T15:26:59.278468Z"
        },
        "trusted": true
      },
      "source": [
        "# Need to know what it works\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:59.280151Z",
          "iopub.execute_input": "2021-11-15T15:26:59.280383Z",
          "iopub.status.idle": "2021-11-15T15:26:59.329225Z",
          "shell.execute_reply.started": "2021-11-15T15:26:59.280358Z",
          "shell.execute_reply": "2021-11-15T15:26:59.328358Z"
        },
        "trusted": true,
        "id": "o1I_Gl7K1jz3"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlRWH3Q8_W3S",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:26:59.330446Z",
          "iopub.execute_input": "2021-11-15T15:26:59.331223Z",
          "iopub.status.idle": "2021-11-15T15:27:00.093492Z",
          "shell.execute_reply.started": "2021-11-15T15:26:59.331171Z",
          "shell.execute_reply": "2021-11-15T15:27:00.092674Z"
        },
        "trusted": true
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-t5kH2zsITZ",
        "execution": {
          "iopub.status.busy": "2021-11-15T15:27:00.095143Z",
          "iopub.execute_input": "2021-11-15T15:27:00.095442Z",
          "iopub.status.idle": "2021-11-15T15:51:20.462209Z",
          "shell.execute_reply.started": "2021-11-15T15:27:00.0954Z",
          "shell.execute_reply": "2021-11-15T15:51:20.461056Z"
        },
        "trusted": true
      },
      "source": [
        "preds = []\n",
        "preds = train_runner(model, train_dataset, dev_dataset, dev_answers, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-10T14:05:08.217021Z",
          "iopub.execute_input": "2021-11-10T14:05:08.217404Z",
          "iopub.status.idle": "2021-11-10T14:05:08.291742Z",
          "shell.execute_reply.started": "2021-11-10T14:05:08.217309Z",
          "shell.execute_reply": "2021-11-10T14:05:08.290539Z"
        },
        "trusted": true,
        "id": "t4CypqIu1jz3"
      },
      "source": [
        "dev_loader = DataLoader(dataset=dev_dataset,\n",
        "                            batch_size=config.batch_size,\n",
        "                            shuffle=False,\n",
        "                            pin_memory=True,\n",
        "                            num_workers=config.num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rnmYoHMsITb",
        "execution": {
          "iopub.status.busy": "2021-11-10T12:54:30.465977Z",
          "iopub.execute_input": "2021-11-10T12:54:30.466216Z",
          "iopub.status.idle": "2021-11-10T12:54:30.476184Z",
          "shell.execute_reply.started": "2021-11-10T12:54:30.466184Z",
          "shell.execute_reply": "2021-11-10T12:54:30.47549Z"
        },
        "trusted": true
      },
      "source": [
        "def read_test_data(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        data_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    guids = []\n",
        "    for group in tqdm(data_dict['data']):\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                guid = qa['guid']\n",
        "                contexts.append(context)\n",
        "                questions.append(question)\n",
        "                guids.append(guid)\n",
        "\n",
        "\n",
        "    return contexts, questions, guids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKcApcSusITb",
        "execution": {
          "iopub.status.busy": "2021-11-10T12:54:30.477866Z",
          "iopub.execute_input": "2021-11-10T12:54:30.478458Z",
          "iopub.status.idle": "2021-11-10T12:54:31.027439Z",
          "shell.execute_reply.started": "2021-11-10T12:54:30.47842Z",
          "shell.execute_reply": "2021-11-10T12:54:31.026754Z"
        },
        "trusted": true
      },
      "source": [
        "test_contexts, test_questions, test_guids = read_test_data(f\"{data_path}/test.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGKBzTpesITb",
        "execution": {
          "iopub.status.busy": "2021-11-10T12:54:31.028743Z",
          "iopub.execute_input": "2021-11-10T12:54:31.029575Z",
          "iopub.status.idle": "2021-11-10T12:54:31.045596Z",
          "shell.execute_reply.started": "2021-11-10T12:54:31.029522Z",
          "shell.execute_reply": "2021-11-10T12:54:31.044917Z"
        },
        "trusted": true
      },
      "source": [
        "def prediction(contexts, questions, guids):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    result = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for context, question, guid in tqdm(zip(contexts, questions, guids)):\n",
        "            if len(context) > 512:\n",
        "                context = context[:512-len(question)-3]\n",
        "            token_type_ids = [1] * (len(context) + 1) + [0] * (len(question) + 2)\n",
        "            \n",
        "            encodings = tokenizer(context, question, max_length=512, truncation='only_first',\n",
        "                                     padding=\"max_length\", return_token_type_ids=False)\n",
        "            encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n",
        "            \n",
        "            input_ids = encodings[\"input_ids\"].to(device)\n",
        "            attention_mask = encodings[\"attention_mask\"].to(device)\n",
        "            \n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            \n",
        "            start_logit, end_logit = outputs.start_logits, outputs.end_logits\n",
        "            start_prob = start_logit[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "            end_prob = end_logit[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "            \n",
        "            probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
        "            index = torch.argmax(probability).cpu()\n",
        "\n",
        "            start = index // len(end_prob)\n",
        "            end = index % len(end_prob)\n",
        "            result.append([guid, start, end])\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP-ekNs0sITc",
        "execution": {
          "iopub.status.busy": "2021-11-10T13:02:10.689621Z",
          "iopub.execute_input": "2021-11-10T13:02:10.689882Z",
          "iopub.status.idle": "2021-11-10T13:26:46.293295Z",
          "shell.execute_reply.started": "2021-11-10T13:02:10.689853Z",
          "shell.execute_reply": "2021-11-10T13:26:46.292595Z"
        },
        "trusted": true
      },
      "source": [
        "pred_idx = prediction(test_contexts, test_questions, test_guids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dAXlGr4sITc",
        "execution": {
          "iopub.status.busy": "2021-11-10T13:31:08.398847Z",
          "iopub.execute_input": "2021-11-10T13:31:08.399548Z",
          "iopub.status.idle": "2021-11-10T13:31:16.823193Z",
          "shell.execute_reply.started": "2021-11-10T13:31:08.39951Z",
          "shell.execute_reply": "2021-11-10T13:31:16.822419Z"
        },
        "trusted": true
      },
      "source": [
        "predictions = []\n",
        "\n",
        "for pred, context, question in zip(pred_idx, test_contexts, test_questions):\n",
        "    position = 0\n",
        "    text = context + '[SEP]' + question\n",
        "    context_position =[]\n",
        "    for morph in tokenizer.tokenize(text):\n",
        "        morph_text_only = morph.replace('#','')\n",
        "        position = context.find(morph_text_only, position)\n",
        "        context_position.append((position, position + len(morph_text_only)))\n",
        "        position += len(morph_text_only)\n",
        "    \n",
        "    start = pred[1] - 1\n",
        "    end = pred[2] - 1\n",
        "    answer = context[context_position[start][0]: context_position[end][1]]\n",
        "    \n",
        "    predictions.append((pred[0], answer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhmIWEGUsITc",
        "execution": {
          "iopub.status.busy": "2021-11-10T13:31:17.050898Z",
          "iopub.execute_input": "2021-11-10T13:31:17.05176Z",
          "iopub.status.idle": "2021-11-10T13:31:17.075471Z",
          "shell.execute_reply.started": "2021-11-10T13:31:17.051713Z",
          "shell.execute_reply": "2021-11-10T13:31:17.074683Z"
        },
        "trusted": true
      },
      "source": [
        "results = pd.DataFrame(predictions, columns = ['ID', 'Predicted'])\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z591SrTeuqBE",
        "execution": {
          "iopub.status.busy": "2021-11-10T13:31:28.028657Z",
          "iopub.execute_input": "2021-11-10T13:31:28.028928Z",
          "iopub.status.idle": "2021-11-10T13:31:28.055648Z",
          "shell.execute_reply.started": "2021-11-10T13:31:28.028899Z",
          "shell.execute_reply": "2021-11-10T13:31:28.054894Z"
        },
        "trusted": true
      },
      "source": [
        "results.to_csv('Your Path', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfIkwz6nnzPV",
        "execution": {
          "iopub.status.busy": "2021-11-10T13:31:30.089191Z",
          "iopub.execute_input": "2021-11-10T13:31:30.089723Z",
          "iopub.status.idle": "2021-11-10T13:31:30.0971Z",
          "shell.execute_reply.started": "2021-11-10T13:31:30.089682Z",
          "shell.execute_reply": "2021-11-10T13:31:30.096379Z"
        },
        "trusted": true
      },
      "source": [
        "def truncation(text):\n",
        "    return text if len(text) < 16 else text[:16]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQToa4XDn7x8",
        "execution": {
          "iopub.status.busy": "2021-11-10T13:31:31.492554Z",
          "iopub.execute_input": "2021-11-10T13:31:31.493417Z",
          "iopub.status.idle": "2021-11-10T13:31:31.503886Z",
          "shell.execute_reply.started": "2021-11-10T13:31:31.49337Z",
          "shell.execute_reply": "2021-11-10T13:31:31.503144Z"
        },
        "trusted": true
      },
      "source": [
        "results['Predicted'] = results['Predicted'].apply(truncation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGrJvl1FsITc",
        "execution": {
          "iopub.status.busy": "2021-11-10T13:31:32.679774Z",
          "iopub.execute_input": "2021-11-10T13:31:32.680463Z",
          "iopub.status.idle": "2021-11-10T13:31:32.702617Z",
          "shell.execute_reply.started": "2021-11-10T13:31:32.680425Z",
          "shell.execute_reply": "2021-11-10T13:31:32.701935Z"
        },
        "trusted": true
      },
      "source": [
        "results.to_csv('Your Path', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}